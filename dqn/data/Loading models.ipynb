{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/Users/alfordsimon/Python/hypothesis-posing-proving/')\n",
    "from deep_rl.utilities.data_structures.Config import Config\n",
    "from bitenvs.reverse_gym_env import ReverseGymEnv\n",
    "from deep_rl.agents.DQN_agents.DQN_HER import DQN_HER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/alfordsimon/Python/hypothesis-posing-proving/dqn/data/reverse_env/models/her_10_3_1_0_(6).pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output_layers.0.weight', 'output_layers.0.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "str_len = 10\n",
    "reverse_len = 3\n",
    "reverse_offset = 1\n",
    "num_obscured = 0\n",
    "\n",
    "config.environment = ReverseGymEnv(str_len, reverse_len, reverse_offset,\n",
    "        num_obscured)\n",
    "config.seed = 1\n",
    "config.num_episodes_to_run = 1000\n",
    "config.show_solution_score = False\n",
    "config.visualise_individual_results = False\n",
    "config.visualise_overall_agent_results = True\n",
    "config.standard_deviation_results = 1.0\n",
    "config.runs_per_agent = 1\n",
    "config.use_GPU = False\n",
    "config.overwrite_existing_results_file = True\n",
    "config.randomise_random_seed = True\n",
    "config.seed = 1\n",
    "\n",
    "config.hyperparameters = {\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 128,\n",
    "        'buffer_size': 100000,\n",
    "        'epsilon_decay_rate_denominator': 150,\n",
    "        'discount_rate': 0.999,\n",
    "        'incremental_td_error': 1e-8,\n",
    "        'update_every_n_steps': 1,\n",
    "        'linear_hidden_units': [64, 64],\n",
    "        'final_layer_activation': None,\n",
    "#        'y_range': (0, 1),\n",
    "        'y_range': (-1, str_len),\n",
    "        'batch_norm': False,\n",
    "        'gradient_clipping_norm': 5,\n",
    "        'HER_sample_proportion': 0.8,\n",
    "        'learning_iterations': 1,\n",
    "        'clip_rewards': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE  ReverseEnv: (10, 3, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "agent = DQN_HER(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = agent.q_network_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep_rl.nn_builder.pytorch.NN.NN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden_layers.0.weight',\n",
       "              tensor([[ 0.1152, -0.0987, -0.0433,  ..., -0.0009,  0.1955,  0.0696],\n",
       "                      [-0.0833, -0.1350, -0.0375,  ..., -0.0372,  0.0957, -0.1039],\n",
       "                      [ 0.2194, -0.0946,  0.1677,  ..., -0.1493,  0.1362,  0.0694],\n",
       "                      ...,\n",
       "                      [-0.0276, -0.1422, -0.0426,  ..., -0.0602, -0.0109, -0.0979],\n",
       "                      [ 0.0306, -0.1441,  0.0920,  ..., -0.0103,  0.1630,  0.0610],\n",
       "                      [ 0.0642,  0.0007, -0.0934,  ..., -0.1899,  0.1434, -0.1382]])),\n",
       "             ('hidden_layers.0.bias',\n",
       "              tensor([ 0.0029, -0.0003,  0.0383, -0.0131,  0.1160,  0.0307,  0.1603,  0.0483,\n",
       "                      -0.0028,  0.0317,  0.1490,  0.0337,  0.1575, -0.0212,  0.0019,  0.1879,\n",
       "                      -0.2111,  0.0223,  0.2042, -0.1122, -0.0412, -0.0135,  0.0737,  0.0845,\n",
       "                       0.0507,  0.0882, -0.0959,  0.0941, -0.0709,  0.1405, -0.0656, -0.1904,\n",
       "                       0.0160,  0.1164, -0.0088,  0.0029,  0.0008,  0.1187,  0.0175, -0.1998,\n",
       "                      -0.1595,  0.0132, -0.0180,  0.2137, -0.0526,  0.1711, -0.1886, -0.2125,\n",
       "                      -0.0206, -0.1416, -0.0652,  0.0252, -0.1940,  0.1537, -0.1357,  0.1716,\n",
       "                       0.0731, -0.0419, -0.1957,  0.0370, -0.1249,  0.1933, -0.1881, -0.0591])),\n",
       "             ('hidden_layers.1.weight',\n",
       "              tensor([[-0.0689, -0.0804, -0.0652,  ..., -0.0779,  0.1199, -0.0589],\n",
       "                      [-0.1039,  0.0859,  0.0485,  ..., -0.0786, -0.0483, -0.0032],\n",
       "                      [ 0.1005, -0.0319,  0.0825,  ..., -0.0693,  0.0029,  0.0380],\n",
       "                      ...,\n",
       "                      [-0.0524,  0.1250, -0.0776,  ..., -0.0818,  0.0244,  0.0477],\n",
       "                      [ 0.0379,  0.0908, -0.1139,  ...,  0.1139,  0.0973, -0.0852],\n",
       "                      [ 0.0371,  0.1086,  0.0074,  ..., -0.0089,  0.0536,  0.0181]])),\n",
       "             ('hidden_layers.1.bias',\n",
       "              tensor([-0.0215,  0.0270, -0.0634,  0.0112, -0.0742,  0.0563,  0.1213, -0.0407,\n",
       "                      -0.1118,  0.1030, -0.0645,  0.0828,  0.0866, -0.0440,  0.0032, -0.0529,\n",
       "                       0.1045, -0.0900,  0.0139, -0.0703,  0.0985,  0.0607,  0.1080, -0.0574,\n",
       "                       0.0423, -0.1066,  0.0743, -0.0415,  0.0417,  0.0607, -0.0784,  0.0702,\n",
       "                      -0.0511,  0.0482, -0.0427,  0.0055,  0.0127,  0.1078,  0.0357,  0.0217,\n",
       "                      -0.0231, -0.1245, -0.0556, -0.0425,  0.0468, -0.0091,  0.0392, -0.0648,\n",
       "                      -0.1244,  0.0458,  0.0675,  0.0661,  0.1036, -0.1219,  0.0372,  0.0993,\n",
       "                      -0.0639,  0.0697,  0.0646,  0.0266, -0.1196,  0.0586,  0.1123, -0.0171])),\n",
       "             ('output_layers.0.weight',\n",
       "              tensor([[ 4.9840e-02,  9.5249e-02, -9.3328e-02, -1.1630e-01,  4.8742e-02,\n",
       "                       -5.2443e-03, -5.8763e-02, -1.1679e-01, -7.7559e-02,  3.3778e-02,\n",
       "                       -2.2998e-02, -1.0862e-01, -1.2646e-02, -6.3215e-03, -1.1664e-01,\n",
       "                        7.4940e-02,  1.2489e-01,  8.8704e-02, -1.1237e-01, -7.6893e-02,\n",
       "                       -9.7684e-02,  1.0529e-01, -5.9247e-02,  9.3134e-02, -5.2011e-02,\n",
       "                        4.9110e-02,  8.8356e-02, -6.0924e-02,  5.4980e-02,  6.1218e-02,\n",
       "                        2.8685e-02, -4.7235e-02, -9.6197e-02,  2.6075e-02, -1.1311e-01,\n",
       "                       -4.1214e-02,  2.0223e-02,  7.7106e-02,  9.5499e-02, -1.0484e-01,\n",
       "                       -5.5364e-02, -1.1234e-02, -2.4425e-03, -2.9974e-02, -7.9248e-02,\n",
       "                       -2.7748e-02, -2.6018e-02, -7.5816e-02,  4.0484e-02, -8.9705e-02,\n",
       "                       -1.0714e-01,  2.2656e-02, -6.1872e-02,  1.1005e-01, -8.1868e-02,\n",
       "                       -8.5100e-02,  1.1658e-01,  2.2812e-02,  1.1971e-01,  1.1034e-01,\n",
       "                        1.2406e-01,  9.5974e-02,  7.3680e-02, -7.5467e-02],\n",
       "                      [-3.5289e-02, -1.2992e-02, -1.1644e-04,  9.7724e-02,  3.7877e-02,\n",
       "                       -1.1607e-01,  3.1590e-02,  7.1590e-03,  5.6555e-02, -5.3414e-02,\n",
       "                        1.0484e-01, -8.8306e-02,  9.7764e-02,  1.1229e-01, -1.0144e-01,\n",
       "                       -8.4451e-02,  8.2183e-02, -9.9573e-02, -7.7621e-03, -7.1654e-02,\n",
       "                        6.5652e-02,  1.1853e-01,  1.0192e-01,  1.0780e-01,  6.8383e-02,\n",
       "                       -1.0708e-01,  3.3880e-02,  1.1440e-01,  7.0379e-02, -7.8196e-02,\n",
       "                        5.3736e-02,  2.7866e-02, -7.7962e-02, -1.0959e-01, -7.0351e-02,\n",
       "                       -9.7247e-02, -4.1649e-02,  1.1787e-02, -6.3188e-02, -3.3397e-02,\n",
       "                       -4.2213e-02,  5.6449e-02, -9.9050e-02,  1.1907e-01,  1.2210e-01,\n",
       "                        1.0673e-01,  9.5633e-02, -1.4206e-02, -6.3280e-02,  1.1764e-01,\n",
       "                       -1.2020e-01, -1.1959e-01,  1.0233e-01, -4.8502e-02,  8.2778e-02,\n",
       "                       -7.1805e-02, -8.4892e-02, -8.9107e-02, -3.7140e-03, -1.8019e-03,\n",
       "                       -4.6083e-02,  2.5610e-02,  7.3706e-02, -5.7177e-02],\n",
       "                      [ 7.1900e-02, -4.7020e-02,  3.7132e-02, -4.0991e-02, -6.6775e-02,\n",
       "                        1.2090e-01, -8.1932e-02,  3.0016e-02, -1.1865e-01,  6.6360e-02,\n",
       "                        8.2767e-02, -1.1883e-01, -8.2548e-02, -1.2019e-01,  3.0746e-02,\n",
       "                       -1.1406e-01,  5.0209e-02,  1.1877e-01, -1.5050e-02,  6.1296e-02,\n",
       "                       -9.9245e-02,  3.9340e-02, -1.5165e-02,  7.2194e-02,  1.2453e-01,\n",
       "                       -9.0738e-02, -1.8271e-02, -7.5356e-02,  5.0464e-02,  1.1216e-01,\n",
       "                       -1.8953e-02,  1.1192e-01,  8.5998e-02, -1.6611e-02,  6.8190e-02,\n",
       "                        1.0501e-01,  8.8699e-03, -1.0511e-01,  3.3954e-02, -1.1189e-01,\n",
       "                        6.9345e-03, -8.3536e-02,  1.1611e-01, -7.2370e-02, -5.8117e-02,\n",
       "                        8.2261e-02, -8.0868e-02,  1.2229e-01,  1.9873e-02,  6.5587e-02,\n",
       "                       -7.4568e-02, -4.4954e-03,  5.7486e-02,  6.2752e-02, -9.7563e-03,\n",
       "                        1.0961e-01,  5.4305e-02, -3.5595e-02, -1.2147e-01,  1.0137e-01,\n",
       "                        9.3620e-02, -6.7978e-02,  5.9602e-03,  5.8344e-02],\n",
       "                      [ 9.4753e-02, -4.8839e-02,  5.5461e-02, -7.1182e-02,  1.0572e-02,\n",
       "                       -2.6319e-02,  2.5299e-02,  7.0425e-02, -3.1717e-03,  9.5406e-02,\n",
       "                       -4.8384e-02, -7.1176e-02,  1.0299e-01,  3.1498e-03, -3.4865e-02,\n",
       "                        3.1417e-02,  2.9929e-02, -1.9613e-02, -6.4725e-02, -6.3467e-02,\n",
       "                       -2.3152e-02,  1.4322e-02, -1.1521e-01,  9.6870e-02, -1.3050e-04,\n",
       "                       -8.6322e-05,  2.8802e-02,  1.9409e-02,  3.0262e-02, -3.4697e-04,\n",
       "                       -1.4407e-02, -8.3246e-02,  5.8918e-02,  1.1509e-01,  8.1421e-02,\n",
       "                       -1.1699e-01,  8.4362e-02,  4.1308e-02, -1.1309e-01,  1.1631e-01,\n",
       "                        1.0145e-01,  1.1119e-01, -1.0998e-01, -3.6843e-02,  9.5658e-03,\n",
       "                       -6.7828e-02, -4.5354e-03, -2.3967e-02,  3.9677e-02, -8.2472e-02,\n",
       "                       -1.2559e-02,  1.0460e-01,  8.2427e-02,  2.8800e-02, -6.6438e-02,\n",
       "                       -7.3479e-02,  1.1053e-01,  1.3925e-02, -8.9816e-03, -1.0368e-01,\n",
       "                       -4.1777e-02, -1.1997e-01,  5.6642e-02,  1.3682e-02],\n",
       "                      [-2.4670e-02,  4.0473e-02,  2.1319e-02,  2.7329e-02,  9.5314e-02,\n",
       "                       -6.8681e-02, -1.0913e-02,  1.0595e-01, -1.0240e-02,  3.3602e-03,\n",
       "                        7.7080e-02,  1.1131e-02, -9.6730e-03,  6.7128e-02,  4.3649e-02,\n",
       "                       -1.2145e-01,  4.8371e-02, -2.3696e-02,  2.1729e-02,  8.1070e-03,\n",
       "                        8.2828e-02, -1.0864e-01,  5.1855e-02,  6.5897e-02, -9.2014e-02,\n",
       "                       -1.3612e-02,  6.5973e-02,  1.9602e-02,  8.2167e-02,  1.0071e-01,\n",
       "                        1.0751e-01,  1.2328e-01,  1.2037e-01, -1.7870e-02, -2.7103e-02,\n",
       "                       -9.0522e-02, -2.7371e-02,  3.5567e-02,  6.4585e-02,  9.2158e-03,\n",
       "                        7.6589e-02,  1.1056e-01,  8.2299e-02,  2.6997e-02, -5.6976e-03,\n",
       "                       -8.2559e-02,  7.2757e-02, -5.3932e-02, -2.6205e-03,  9.7024e-02,\n",
       "                        1.2408e-01, -1.3787e-02,  8.8743e-02,  1.0106e-01, -7.8811e-02,\n",
       "                       -1.7885e-02,  4.2778e-02,  8.1039e-02, -9.2976e-02, -4.6162e-02,\n",
       "                        9.1827e-02,  9.6648e-02, -5.3651e-02,  7.4357e-02],\n",
       "                      [ 1.0861e-02, -5.5478e-02,  5.7002e-02,  9.6886e-02, -9.1287e-02,\n",
       "                       -8.3461e-02,  9.4099e-02,  6.2000e-03,  6.5116e-02, -1.0112e-01,\n",
       "                       -9.8519e-02,  8.9244e-02,  2.9150e-03,  7.8969e-03, -5.0571e-02,\n",
       "                        7.4414e-02,  2.9854e-02, -1.2115e-01,  6.2777e-02,  1.5185e-02,\n",
       "                       -4.9378e-02,  9.0130e-02,  4.7380e-02,  5.1878e-02, -9.4481e-02,\n",
       "                        6.8785e-02, -1.0627e-01, -5.0555e-02,  3.8168e-02, -6.5566e-02,\n",
       "                        7.3051e-02,  6.9984e-02,  2.2457e-02,  9.0377e-02, -5.0159e-03,\n",
       "                       -3.9688e-02,  8.3884e-02, -2.1039e-04, -7.3814e-02, -5.1568e-02,\n",
       "                        3.8710e-02, -1.1467e-02, -2.3227e-02,  4.5244e-02, -1.1778e-01,\n",
       "                       -4.5592e-02, -1.1956e-01,  5.8544e-03,  3.6280e-02,  2.1411e-02,\n",
       "                        1.2824e-02,  3.4114e-02,  2.2460e-02,  2.9153e-02, -4.5543e-02,\n",
       "                        1.0849e-01, -4.0421e-02,  6.0535e-02,  1.1936e-01,  1.7235e-02,\n",
       "                       -6.9463e-02, -3.0432e-02, -1.1297e-01, -8.6297e-02],\n",
       "                      [ 1.2866e-02,  1.0528e-01, -2.1251e-02, -6.8538e-03,  9.1840e-03,\n",
       "                       -6.5652e-02, -6.0446e-02, -9.4245e-02, -7.4572e-03,  3.5907e-02,\n",
       "                        8.9235e-02, -1.2306e-01,  6.3630e-02, -1.0362e-01,  6.0355e-02,\n",
       "                       -8.6832e-02, -8.0104e-02, -1.0334e-01,  1.0581e-01, -1.0379e-01,\n",
       "                        8.5210e-02,  1.0761e-01, -8.1295e-02,  9.0682e-02,  1.1473e-01,\n",
       "                       -1.2039e-01, -8.1046e-02,  9.4500e-02, -7.6060e-02,  8.2154e-02,\n",
       "                       -7.2318e-02, -1.9326e-02, -8.0228e-02,  1.8969e-02, -7.6141e-02,\n",
       "                       -6.9980e-02,  2.3069e-02, -4.3577e-03, -8.0398e-03, -6.0929e-02,\n",
       "                        7.2502e-02,  1.1466e-01,  7.4546e-02, -9.7419e-02, -1.0265e-01,\n",
       "                       -7.9588e-02,  6.4725e-03, -8.2173e-03,  1.7660e-02,  4.0794e-02,\n",
       "                        7.5414e-02,  6.2022e-02,  3.2095e-02, -3.9384e-02, -1.1270e-02,\n",
       "                       -4.0541e-02, -9.0400e-02, -1.5232e-02, -1.1632e-01,  9.3757e-02,\n",
       "                        8.8207e-02,  7.4653e-03, -8.3123e-02, -3.7384e-02],\n",
       "                      [ 3.0457e-02,  9.9969e-02,  1.0400e-01,  3.8958e-02,  5.6294e-02,\n",
       "                       -3.1686e-02, -8.4020e-02, -6.3417e-02, -4.4519e-02,  1.6414e-02,\n",
       "                        1.5338e-03,  8.2719e-02,  1.0962e-01, -8.8222e-02,  5.2631e-02,\n",
       "                       -4.4584e-02,  6.0670e-02, -1.1789e-01, -3.8310e-02,  7.0080e-02,\n",
       "                       -2.7302e-02, -6.2924e-02,  9.1942e-02, -7.8729e-02, -8.4052e-02,\n",
       "                       -7.3369e-03,  6.5017e-02, -8.1750e-02,  8.4320e-02, -1.2100e-01,\n",
       "                        9.6466e-02, -9.2873e-02,  6.7366e-03, -8.4008e-02, -1.0514e-01,\n",
       "                        1.2295e-01,  5.1969e-02, -1.0500e-01, -1.0972e-01, -6.6729e-03,\n",
       "                        8.0403e-02,  6.9512e-02,  5.5025e-03,  1.6217e-02, -9.2474e-02,\n",
       "                        7.6220e-02, -1.3418e-02, -1.0066e-01, -9.1981e-02, -2.5750e-02,\n",
       "                       -7.8735e-02, -4.0291e-02,  1.2197e-01,  5.3739e-03, -6.7844e-02,\n",
       "                        9.7453e-02,  1.1603e-01,  1.2146e-02, -3.1340e-03,  1.4816e-02,\n",
       "                       -2.5194e-02,  2.3206e-02,  3.8953e-02,  9.4349e-02]])),\n",
       "             ('output_layers.0.bias',\n",
       "              tensor([ 0.0588,  0.0246, -0.0094,  0.0955,  0.0507,  0.0396,  0.0856,  0.0258]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'output_layers.0.weight', 'output_layers.0.bias'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0322, -0.7578,  0.0467, -0.8248, -0.0199,  0.3776, -0.0124,  0.5225,\n",
       "         0.1582,  0.6630, -0.0744,  0.7493, -0.0403,  0.4297, -0.0054, -0.3248,\n",
       "        -0.0129, -0.5334, -0.1287, -0.6377])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['hidden_layers.0.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('hidden_layers.0.weight',\n",
       "              tensor([[-0.2084, -0.4238,  0.2642,  ...,  0.0999, -0.0078, -0.1226],\n",
       "                      [ 0.1094,  0.0145,  0.0641,  ..., -0.0531, -0.0602, -0.9345],\n",
       "                      [ 0.3353, -0.0599,  0.0954,  ...,  0.3941,  0.2766,  0.5709],\n",
       "                      ...,\n",
       "                      [-0.0328, -0.0219, -0.2072,  ..., -0.5513, -0.0165, -0.1559],\n",
       "                      [-0.4279,  0.4932, -0.0480,  ...,  0.2084, -0.0867,  0.1693],\n",
       "                      [-0.4155, -0.2256,  0.2310,  ..., -0.0027,  0.4370,  0.2058]])),\n",
       "             ('hidden_layers.0.bias',\n",
       "              tensor([-0.0712,  0.1675,  0.0217,  0.1452,  0.1612,  0.2155, -0.0125, -0.0009,\n",
       "                       0.1048, -0.0018, -0.1719,  0.1087,  0.0129, -0.1081, -0.1134, -0.1516,\n",
       "                       0.0382,  0.1038,  0.1626, -0.3152,  0.0287,  0.3234,  0.0356, -0.0989,\n",
       "                       0.0018, -0.0649, -0.0088, -0.0807,  0.0857, -0.2188, -0.0308, -0.1498,\n",
       "                       0.0175, -0.0673, -0.0727,  0.1137,  0.1089, -0.0391,  0.0678,  0.0484,\n",
       "                       0.0034, -0.0535, -0.1147,  0.1092, -0.0877,  0.2684,  0.1616,  0.0867,\n",
       "                      -0.0723, -0.0186,  0.2535,  0.0980,  0.0040,  0.0724, -0.2063, -0.1833,\n",
       "                      -0.0908, -0.0404, -0.1753,  0.0432, -0.0585,  0.0122, -0.0791, -0.1597])),\n",
       "             ('hidden_layers.1.weight',\n",
       "              tensor([[ 0.2009,  0.1858,  0.0271,  ...,  0.1428,  0.1320, -0.2411],\n",
       "                      [ 0.2683,  0.3493, -0.1536,  ...,  0.1968, -0.6228, -0.0512],\n",
       "                      [-0.0929,  0.3124,  0.1845,  ..., -0.0873,  0.2412,  0.0447],\n",
       "                      ...,\n",
       "                      [ 0.1834,  0.0580, -0.0308,  ...,  0.0125, -0.1534,  0.3017],\n",
       "                      [ 0.0350,  0.2711,  0.1089,  ..., -0.2121,  0.0779, -0.0975],\n",
       "                      [-0.0545, -0.4155,  0.1549,  ...,  0.1433,  0.1655, -0.0809]])),\n",
       "             ('hidden_layers.1.bias',\n",
       "              tensor([-0.0294, -0.0962, -0.0720,  0.0911,  0.1187, -0.1470,  0.1636, -0.0872,\n",
       "                       0.1628,  0.2129, -0.0273, -0.0097,  0.1622,  0.1054, -0.0708,  0.0938,\n",
       "                      -0.0056,  0.0093,  0.0691, -0.0337, -0.0407,  0.0474,  0.0571, -0.0965,\n",
       "                       0.1296,  0.1203,  0.0486,  0.0147,  0.0608,  0.0118, -0.0008, -0.0636,\n",
       "                       0.0475, -0.0815, -0.0540, -0.0629,  0.1751, -0.1406,  0.0029,  0.0215,\n",
       "                       0.0700,  0.0514, -0.0609, -0.0877, -0.0671,  0.1914, -0.0501, -0.1412,\n",
       "                      -0.0942, -0.1175,  0.0420,  0.1489, -0.0791,  0.1330,  0.0260, -0.0893,\n",
       "                      -0.0874, -0.1107, -0.0246,  0.0252,  0.1528,  0.1840,  0.0508,  0.0755])),\n",
       "             ('output_layers.0.weight',\n",
       "              tensor([[-3.5533e-01, -4.0683e-01, -2.0611e-01,  1.6952e-01,  5.4921e-03,\n",
       "                       -2.4050e-01, -3.7742e-01,  8.4458e-02,  6.0316e-01,  1.1260e-01,\n",
       "                       -1.0672e-01,  4.5171e-01,  4.2810e-01,  3.7378e-01,  6.0100e-01,\n",
       "                        1.9761e-01, -4.5023e-02, -1.4056e-01, -1.4643e-01,  1.6648e-01,\n",
       "                       -1.8721e-01, -4.0132e-02,  5.6891e-01,  4.1329e-01,  2.4899e-01,\n",
       "                        1.6138e-01, -1.8608e-01,  2.5474e+00,  5.3029e-01,  1.5299e-01,\n",
       "                        1.0341e-01, -6.5100e-01, -1.3523e-01,  1.0985e-01, -4.1482e-02,\n",
       "                        1.4957e-01,  3.9420e-01, -8.1751e-02,  7.7103e-02, -2.6034e-01,\n",
       "                        1.5662e-01,  1.3812e-01, -1.9459e-01, -4.1075e-02, -1.9391e-01,\n",
       "                       -5.4942e-02, -3.5566e-01,  1.5138e-02,  6.8135e-03,  2.0137e-01,\n",
       "                        7.0862e-02,  1.5976e-01,  1.3669e-01, -8.5022e-04, -2.3328e-01,\n",
       "                        7.9816e-02,  4.8589e-02,  3.6351e-02,  1.7503e+00,  1.5412e-01,\n",
       "                        2.0810e-01, -6.8331e-02, -1.6942e-01,  1.1920e-01],\n",
       "                      [ 4.1813e-01,  6.4075e-01,  7.4435e-02,  2.6810e-01,  1.2577e-01,\n",
       "                       -7.3542e-02, -2.9639e-01, -1.9092e-01,  1.5237e-01, -1.1034e-01,\n",
       "                        1.4494e-01,  2.9392e-01, -7.6166e-02,  3.5244e+00,  3.5638e-01,\n",
       "                        1.7384e-01, -6.2230e-02, -1.5421e-01, -4.4766e-01, -2.2194e-01,\n",
       "                       -2.3688e-01, -2.7982e-01,  4.6694e-01,  1.6522e-01, -6.2933e-02,\n",
       "                       -1.3235e-01,  4.7166e-01, -3.6770e-01,  1.4977e-01,  8.9502e-02,\n",
       "                        2.3385e-01,  2.3113e-01, -3.2465e-01, -1.4450e-01,  4.1459e-02,\n",
       "                       -3.6892e-01,  1.3316e-01,  9.8496e-02, -1.9535e-01, -2.0733e-02,\n",
       "                        1.6361e-01,  6.2362e-02, -9.1091e-02,  8.9473e-02,  1.6226e-01,\n",
       "                        4.9623e-02, -7.7134e-02, -1.3909e-01, -5.4751e-02, -1.7720e-01,\n",
       "                        1.1235e-01,  3.0676e-01, -1.2344e-01,  1.1625e+00, -2.6933e-01,\n",
       "                       -7.9443e-01, -9.8201e-03, -9.8394e-03,  1.4236e+00,  2.5450e-01,\n",
       "                        4.9769e-01,  3.4059e-01, -7.2984e-02, -6.3647e-02],\n",
       "                      [-7.8046e-02,  2.6426e-01,  4.1913e-01, -2.7260e-01,  1.0129e-01,\n",
       "                        2.5644e-01, -2.8741e-01, -4.4250e-02, -3.0097e-01, -3.0829e-01,\n",
       "                       -4.1357e-02,  6.0641e-01,  4.3855e-01,  2.2571e+00,  3.2019e-01,\n",
       "                        1.6650e-01,  8.9831e-02,  3.5063e-02,  4.0130e-01, -2.6673e-01,\n",
       "                        2.0363e-01, -3.5136e-01, -1.4062e-01,  4.1385e-01,  9.5574e-02,\n",
       "                       -1.4498e-03, -3.4576e-01, -2.3205e-01,  7.4458e-01, -3.7977e-02,\n",
       "                       -2.3288e-01,  4.8477e-01, -2.8644e-01,  6.5209e-01, -3.3104e-02,\n",
       "                        4.2883e-01, -3.7795e-01,  9.8077e-03,  4.0284e-01, -9.9918e-02,\n",
       "                        2.5964e-01,  2.0970e-01, -7.4339e-02,  5.8996e-01,  1.1489e-01,\n",
       "                       -2.5525e-01,  5.5945e-02,  5.1678e-02, -5.6495e-03,  3.1706e-01,\n",
       "                       -1.7347e-01,  1.6896e-01, -8.7074e-02, -2.4932e-01, -1.8359e-01,\n",
       "                        8.1900e-02,  2.1431e-02, -4.4254e-02,  1.8863e+00, -1.2490e-02,\n",
       "                        1.5629e-01, -1.3449e-01, -2.5168e-02, -1.5532e-01],\n",
       "                      [-4.4547e-01, -2.0466e-01,  1.2973e-01,  6.2404e-02,  2.0453e-01,\n",
       "                       -3.6078e-01, -4.0705e-02, -1.5704e-01, -4.2430e-02, -3.7197e-01,\n",
       "                        2.0745e-01, -7.3720e-02,  3.1362e-01,  7.0886e-01,  2.2311e-01,\n",
       "                        1.3405e-01,  2.1718e-01,  4.6561e-01,  9.0268e-01, -3.7421e-01,\n",
       "                       -4.0278e-02, -2.6268e-01,  1.0658e+00,  3.2396e-01,  9.9133e-02,\n",
       "                       -4.8043e-02, -1.3188e-01,  2.7213e+00, -4.4676e-01,  2.1290e-01,\n",
       "                       -1.2778e-01, -4.8280e-01,  2.3115e-02, -5.4574e-01,  1.2230e-01,\n",
       "                       -1.4454e-01, -1.7644e-02,  9.4140e-03,  9.1811e-01,  1.2270e-01,\n",
       "                        4.4495e-02,  1.8221e-01, -2.2085e-01, -4.2456e-01, -1.7077e-01,\n",
       "                        4.9598e-01, -7.3937e-02, -1.4056e-01, -7.6652e-03,  2.4651e-01,\n",
       "                        5.2359e-01,  6.2231e-02, -1.8617e-01,  2.1321e-01, -2.5328e-02,\n",
       "                        2.2090e-02,  5.3977e-03,  1.2700e-01,  1.0654e+00,  1.6190e-02,\n",
       "                        4.7417e-01,  1.6755e-01, -1.3789e-01, -1.6941e-01],\n",
       "                      [ 8.7605e-02,  1.3322e-01,  2.2512e-01,  4.4677e-02,  2.0930e-01,\n",
       "                        2.7859e-01, -3.4080e-01,  3.9955e-02,  4.3565e-01, -3.2748e-01,\n",
       "                        7.1521e-03,  1.0037e+00,  4.8573e-01,  1.0680e+00,  5.1322e-02,\n",
       "                       -9.4030e-03,  5.0652e-02, -1.2847e-01,  4.9708e-01,  3.1983e-01,\n",
       "                       -2.0013e-01, -1.5731e-01,  1.0888e+00,  1.0531e-01,  1.2173e-02,\n",
       "                        1.9182e-01,  1.6376e+00, -5.1164e-01, -1.5593e-01,  2.2904e-01,\n",
       "                        5.9608e-03,  5.3163e-01, -2.0060e-01,  1.7577e+00, -7.6201e-01,\n",
       "                       -1.7827e-02,  2.1793e-01, -8.7553e-02,  1.3274e-01, -1.9952e-02,\n",
       "                       -8.4789e-02,  3.3427e-02,  3.4569e-01, -6.4440e-01, -4.5938e-02,\n",
       "                        1.7702e-01, -1.3598e-01, -1.9036e-01, -5.6846e-02, -2.1468e-01,\n",
       "                        2.1759e-01,  7.0544e-02, -1.3005e-01, -2.5085e-01, -7.8237e-02,\n",
       "                        2.3242e-01,  7.7223e-02,  4.2124e-02, -3.5445e-01,  1.9940e-01,\n",
       "                        3.8910e-01,  3.0754e-01,  8.7321e-02, -3.5578e-01],\n",
       "                      [-1.5790e-01, -1.4455e-01,  2.5417e-01,  2.7638e-01,  2.5665e-01,\n",
       "                       -1.3119e-01,  4.2406e-01, -2.7677e-02,  2.1994e-01,  1.5326e-01,\n",
       "                       -1.2242e-01,  1.7239e-02,  2.4529e-01,  4.3296e+00, -5.0916e-01,\n",
       "                        1.6734e-01, -2.3294e-01, -9.2956e-02,  9.8501e-02,  1.1800e-01,\n",
       "                       -4.2324e-01,  3.8538e-01,  2.5454e-01,  3.9127e-01,  1.4648e-01,\n",
       "                        2.1960e-01, -2.6350e-01, -3.0974e-01,  3.5329e-01,  1.1927e-01,\n",
       "                       -6.2772e-01,  4.6818e-01, -1.6244e-01, -4.2848e-01, -1.1034e-01,\n",
       "                        4.3273e-01,  6.7947e-01,  8.3621e-02, -4.2987e-01,  8.0583e-02,\n",
       "                        5.9572e-02,  5.0902e-01, -3.9905e-02,  4.4347e-02, -1.1322e-01,\n",
       "                       -1.7210e-01, -1.1030e-01, -2.5117e-01,  5.2150e-02, -2.3358e-01,\n",
       "                        4.8409e-02,  2.4323e-02, -2.9178e-01,  1.1140e+00, -4.8301e-02,\n",
       "                        7.0994e-02,  1.1011e-01,  1.2839e-01,  5.0318e-01,  1.0663e-01,\n",
       "                        4.5088e-01,  1.1966e-01, -2.7601e-01, -1.8626e-01],\n",
       "                      [-6.1896e-01,  3.3793e-01,  7.8048e-02,  1.7517e-01,  1.2019e-01,\n",
       "                        3.6130e-01,  3.7031e-01,  2.2440e-01,  1.0621e-02,  7.0027e-02,\n",
       "                        1.1358e-01,  7.3376e-01,  2.6108e-01,  1.9351e+00,  7.8982e-01,\n",
       "                       -1.3594e-02,  4.8991e-02,  2.4257e-01,  1.0735e-01, -4.1278e-01,\n",
       "                       -2.2951e-02, -5.2363e-01,  2.5771e-01, -9.4108e-03,  1.3507e-01,\n",
       "                       -4.9976e-02,  2.3435e+00,  5.5587e-01,  2.6270e-01,  1.3212e-01,\n",
       "                        1.0160e-01, -6.7467e-01,  8.0137e-02,  1.0484e+00,  1.7556e-01,\n",
       "                        1.3103e-01,  5.1885e-01,  1.1017e-01,  1.7033e-03, -1.8049e-01,\n",
       "                        6.5845e-02,  4.5249e-02, -2.4059e-02,  2.4089e-01,  8.8210e-02,\n",
       "                        3.2592e-02, -2.6254e-01, -1.0115e-01,  1.2534e-01,  3.1360e-01,\n",
       "                        3.0756e-01,  1.0462e-01, -2.3462e-01,  3.3884e-01, -3.6222e-01,\n",
       "                        7.3844e-03, -1.3949e-02, -3.0690e-02, -1.0269e+00,  2.6599e-01,\n",
       "                       -5.1384e-03,  2.4879e-01, -4.1132e-01, -1.1689e-01],\n",
       "                      [-1.8748e-01,  8.4954e-02,  9.0998e-02,  4.8635e-02,  1.8109e-01,\n",
       "                       -2.9092e-02,  5.4783e-02, -1.4937e-01,  1.5624e-01, -7.3871e-02,\n",
       "                       -1.2451e+00, -3.6385e-01,  2.0518e-01,  3.2752e+00,  3.8173e-01,\n",
       "                        2.1254e-01, -1.1622e-01,  4.4618e-01, -2.4454e-01,  9.6673e-02,\n",
       "                       -1.2800e-01, -1.9532e-01,  3.4960e-01, -3.7703e-02,  2.2286e-01,\n",
       "                        3.3358e-01,  8.1628e-01,  9.7612e-01,  2.9644e-01,  4.0576e-03,\n",
       "                       -7.8407e-02,  6.2463e-01,  1.2096e-01,  5.0977e-01, -1.5718e-01,\n",
       "                       -6.3103e-02, -8.8106e-02,  7.3589e-02,  5.6533e-02, -2.9853e-01,\n",
       "                        3.0750e-01, -1.5641e-01, -9.6707e-02,  1.8688e-01,  1.8270e-03,\n",
       "                        2.0835e-01, -6.7855e-02, -2.2200e-02, -1.5108e-02, -6.7180e-02,\n",
       "                        5.8696e-01,  1.6132e-01,  1.7854e-01, -3.1494e-01, -1.9343e-01,\n",
       "                        2.0551e-01,  1.9792e-02, -7.7013e-02, -1.1464e+00, -1.2910e-01,\n",
       "                        2.5903e-01,  3.4596e-01, -2.1253e-01,  2.0597e-02]])),\n",
       "             ('output_layers.0.bias',\n",
       "              tensor([ 0.0432,  0.1936,  0.1209,  0.0911, -0.0163,  0.0548,  0.0414,  0.0384]))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode 100, Score:  10.00, Max score seen:  2.00, Rolling score:  9.16, Max rolling score seen:  8.62\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" \n",
      "\u001b[91m\u001b[1mDQN-HER did not achieve required score \n",
      "\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "file must have a 'write' attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d6408e544aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_n_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Python/hypothesis-posing-proving/deep_rl/agents/Base_Agent.py\u001b[0m in \u001b[0;36mrun_n_episodes\u001b[0;34m(self, num_episodes, show_whether_achieved_goal, save_and_print_results)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshow_whether_achieved_goal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_whether_achieved_goal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocally_save_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_full_episode_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/hypothesis-posing-proving/deep_rl/agents/DQN_agents/DQN.py\u001b[0m in \u001b[0;36mlocally_save_policy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlocally_save_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;34m\"\"\"Saves the policy\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_network_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_to_save_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved model parameters at '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_to_save_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/pytorch/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    290\u001b[0m     )\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROTOCOL_VERSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute"
     ]
    }
   ],
   "source": [
    "agent.run_n_episodes(num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

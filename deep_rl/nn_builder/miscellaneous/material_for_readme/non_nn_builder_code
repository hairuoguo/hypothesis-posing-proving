# Without nn_builder
import torch.nn as nn

class NN(nn.Module):
    def __init__(self):
        nn.Module.__init__(self)

        self.fc1 = nn.Linear(25, 150)
        self.fc2 = nn.Linear(150, 100)
        self.fc3 = nn.Linear(100, 50)
        self.fc4 = nn.Linear(50, 50)
        self.fc5 = nn.Linear(50, 50)
        self.fc6 = nn.Linear(50, 50)
        self.fc7 = nn.Linear(50, 5)

        self.bn1 = nn.BatchNorm1d(150)
        self.bn2 = nn.BatchNorm1d(100)
        self.bn3 = nn.BatchNorm1d(50)
        self.bn4 = nn.BatchNorm1d(50)
        self.bn5 = nn.BatchNorm1d(50)
        self.bn6 = nn.BatchNorm1d(50)

        self.dropout = nn.Dropout(p=0.5)

        for params in [self.fc1, self.fc2, self.fc3, self.fc4, self.fc5,
                       self.fc6, self.fc7]:
                       nn.init.xavier_uniform_(params.weight)

    def forward(self, x):
        x = self.dropout(self.bn1(nn.ReLU()(self.fc1(x))))
        x = self.dropout(self.bn2(nn.ReLU()(self.fc2(x))))
        x = self.dropout(self.bn3(nn.ReLU()(self.fc3(x))))
        x = self.dropout(self.bn4(nn.ReLU()(self.fc4(x))))
        x = self.dropout(self.bn5(nn.ReLU()(self.fc5(x))))
        x = self.dropout(self.bn6(nn.ReLU()(self.fc6(x))))
        x = self.fc7(x)
        x = nn.Softmax(dim=1)(x)
        return x

model = NN()
